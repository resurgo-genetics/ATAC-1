---
title: "A7-all-ttreg"
author: "JRD"
date: "March 7, 2016"
output: html_document
---

last modified: `r Sys.Date()`
<br>    

#### README
+ this document contains code and explanation for an analysis comparing Colon, Muscle, Splenic and VAT Treg
+ for details on how the input files used in this analysis were generated, see *ATAC_mapping.Rmd* and *ATAC_peaks.Rmd*
+ **difference between A5 and A6 is latter filters peaks by both min signal and replicate CV**
<br>    


#### R Markdown Specifications
Set global options
```{r setoptions, echo=F}
library(knitr)
opts_chunk$set(echo=F, eval=F, warning=F, message=F)
```
<br>    

Github
https://github.com/jdis24/ATAC.git
<br>    


#### JD's stat calculation functions
```{r stat_fxns}
# calculate stats over all numeric columns of df 
row_stats <- function(df) {
  nums <- sapply(df, is.numeric) # extract numeric cols of df

  df_nums <- df[,nums] # subset df by numeric cols
  df_nums <- as.data.frame(apply(df_nums, 2, log,2)) # convert expression to log2

  stats <- transmute_(df_nums, 
                      Mean = ~rowMeans(df_nums),
                      SD = ~rowSds(as.matrix(df_nums)))
  CV <- stats$SD / stats$Mean

  df_other <- df[!nums]     
  cbind(df_other,stats,CV)
}

# calculate stats over any columns of df 
library(matrixStats)
row_stats2 <- function(df,v1,v2) {
  # v1 and v2 must put column numbe in quotes
  nums <- sapply(df, is.numeric) # extract numeric cols of df

  subset <- df[,v1:v2] # subset df by columns

  log2subset <- as.data.frame(apply(subset,2,log,2))

  means <- transmute_(subset,
                      mean = ~rowMeans(subset),
                      log2mean = ~log(rowMeans(subset),2),
                      log10mean = ~log(rowMeans(subset),10))
  meanlog2 <- transmute_(log2subset,
                         meanlog2 = ~rowMeans(log2subset))
  sd <- transmute_(subset,
                      SD = ~rowSds(as.matrix(subset)))
  sd2 <- transmute_(log2subset,
                      SD = ~rowSds(as.matrix(log2subset)))

  cv <- sd$SD / means$mean

  cv2 <- sd2$SD / meanlog2$mean

  #df_other <- df[!nums]
  cbind(PeakID = df$PeakID, subset,means,meanlog2,cv,cv2)
}
```
<br>  



#### Pseudo
**call peaks and get read counts**
+ [these steps were done in "ATAC_peaks.Rmd"]
+ for each sample, call peaks in each replicate
+ then merge into single peakset
+ for each replicate, count reads in each peak, normalized to total library size
+ export .csv files of peaks and counts
**filter for strong peaks, merge peaks and get read counts for merged peaks**
+ [all subsequent steps done in this document]
+ plot distributions of read counts 
+ filter for strong peaks (start with >=2.5 rpm) 
+ filter for peaks with 
+ get genomic annotations of confident strong peaks (compare to unfilterd to check degree of TSS enrichment)

**merge and get read counts for merged peaks**
+ use DiffBind to create merged peakset across all T-treg and get read counts
+ export all peaks and their rpkm score in each sample 
**filter for peaks with low cv**
+ plot replicate rpkm values as scatter plots
+ plot mean vs cv for each set of replicates
+ use distributions to choose cv cutoff
+ filter on cv (start with cv <= 0.6)
+ plot replicate rpkm values post-filter
+ export all peaks and their stats for each sample
**check that filters worked on genome browser**
+ load .bigwig files for each sample with replicates
** quantile normalize read count scores**
+ start with rpm+cv-filtered peak set
+ plot read count distributions before qn
+ use bioconductor function to qn
+ plot read count distributions after qn
<br>  


#### Import peak files into peak list and export bed files
```{r peak_list, eval=T}
# create path to .csv files  
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Master_peaks/R/peaks_with_counts/working/"

# get filenames
filenames1 <- list.files(path = path, pattern = ".csv")
filenames <- paste(path, filenames1, sep="") # update filenames with path

# combine peak table .csv dfs into a list
colClass <- c(rep("factor",2), rep("numeric",3), "character", rep("numeric",4)) # set column classes
pl <- lapply(filenames, read.csv, colClasses = colClass) # [p]eak [l]ist

# name the list elements to match the files
names(pl) <- gsub("\\.csv", "", filenames1)

# convert each df to bed format
pl_bed <- lapply(pl, function(x) {
  x <- x[,c("seqnames","start","end")]
})

# export each df as tdt bed file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/bed/"

lapply(names(pl_bed),
       function(x) write.table(pl_bed[x], file=paste(paste0(path,x),"bed",sep="."), sep = "\t", 
                              quote=F, row.names=F,col.names=c("#chr","start","end")))
```
<br>    


#### Generate table of peak numbers for range of rpm threshold values
```{r threshold_table, eval=T, results="asis"}
library(xtable)

# function to compute the number of peaks >=n rpm in each sample
# ARGS: df = dataframe of peak height rpms, peak_height_var = string of var name storing rpm values, cutoffs = numeric vector of rpm cutoffs 
# USAGE: number_peaks_above_nrpm(df, "peak_height_var", cutoffs)
number_peaks_above_nrpm <- function(df, rpm_var, cutoffs) { 
  # create indexing vector representing number of elements in cutoffs
  n <- length(cutoffs) 
  # create output vector whose length = length of cutoffs
  o <- numeric(n) 
  # create variable to store vector of extracted rpm values
  rpm <- df[[rpm_var]]
  # loop over each element of cutoffs and count number rows where peak height >= that element
  for(i in 1:n) { 
    o[i] <- as.numeric(sum(rpm >= cutoffs[[i]])) # calculate the total number of rows where rpm >= ith value in cutoffs  
  }
  # print output vector
  return(o) 
}


# create cutoff vector of rpm values
cutoffs <- c(seq(0,5,by=0.5))

# apply cutoffs to list
peaks_pass_filter <- sapply(pl, number_peaks_above_nrpm, "rpm", cutoffs)

# transform list into dataframe 
ppf <- as.data.frame(peaks_pass_filter) #[p]eaks [p]ass [f]ilter
ppf <- cbind(ppf,"rpm_cutoff" = cutoffs) # add column for each cutoff

# write to file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/plots/"
write.csv(ppf, file = paste0(path,"peak_totals_rpm_filtered.csv"), row.names=F)

# generate xtable
print(xtable(ppf), type="html", include.rownames=F)

# plot distributions of total peaks called at each cutoff
library(reshape2)
library(ggplot2)

ppfm <- melt(ppf, id.vars='rpm_cutoff',variable.name='no_peaks') # ppf[m]elted 
g <- ggplot(ppfm, aes(x=as.factor(rpm_cutoff),y=value))
g + geom_boxplot() +
  theme_bw()
ggsave(paste0(path, "a7-peakcut-boxplot.pdf"), width=7, height=5) # export pdf
```
<br>    


#### Plot distribution of read counts for each sample
```{r plots, eval=T}
library(reshape2)
library(ggplot2)
library(dplyr)
# set path for plots 
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/plots/"

# get peak list into shape for plotting
plm <- melt(pl, id.vars=names(pl[[1]])) # [p]eak [l]ist [m]elted
plm$L1 <- NULL # remove extraneous column

# calculcate log2 rpm values and append as new column
plm$log2_rpm <- log(plm$rpm, 2)

# show number of peaks where rpm =0 
rpm0pks <- plm$log2_rpm == "-Inf"
plm_rpm0pks <- plm[rpm0pks,]

print("Peaks where rpm =0 ...") 
xtable(plm_rpm0pks)

# filter out peaks where rpm = 0
plmf <- plm[!rpm0pks,]  #plm[f]iltered

# draw boxplot of all peaks in each sample
g <- ggplot(data = plmf, aes(x=Sample, y=log2_rpm, fill=Sample))
g + geom_boxplot(varwidth =T) +
  theme_bw() + 
  ylim(-2,10) +
  theme(axis.title.x = element_blank())
ggsave(paste0(path, "a7-boxplot.pdf"), width=7, height=5) # export pdf

# draw boxplot of peaks passing n rpm
# define function to filter peaks and draw plot
bp_nrpm <- function(df, n) {
  df %>%
    filter(rpm >= n) %>% # filter by rpm cutoff 
    ggplot(aes(x=Sample, y=log2_rpm, fill=Sample)) + # plot
    geom_boxplot(varwidth=T) +
    ylim(-2,10) +
    theme_bw() + 
    theme(axis.title.x = element_blank())
}

n <- 2 # set rpm cutoff
bp_nrpm(plmf, n) # draw plot
ggsave(paste0(path,"a7-boxplot-",n,"rpm-filtered.pdf"), width =7, height =5) # export pdf

# draw histograms of all peaks in each sample
g <- ggplot(data = plmf, aes(x=log2_rpm))
g + geom_histogram(fill="white",color="black",binwidth=0.1) +
  facet_grid(Sample~.) +
  geom_vline(xintercept =log(1,2)) +
  geom_vline(xintercept = log(2,2)) +
  geom_vline(xintercept = log(3,2)) +
  theme_bw()
ggsave(paste0(path, "a7-count-hist.pdf"), width=5, height=25)
```
<br>    


#### Filter for strong peaks
```{r filter_peaks, eval=T}
library(dplyr)
# select peaks >= nrpm
n <- 2
sp <- lapply(pl, filter, rpm >=n) #[s]trong[p]eaks

# export each df as .csv file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/csv/"
suffix <- paste(n,'rpm','.csv',sep="")
lapply(names(sp),
       function(x) write.csv(sp[[x]], file=paste(path,x,'-',suffix,sep=""), row.names=F))

# convert each df to bed format
spbed <- lapply(sp, function(x) {
  x <- x[,c("seqnames","start","end")]
})

# export each df as tdt bed file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-filtered/bed/"

suffix <- paste(n, 'rpm','.bed',sep="")
lapply(names(spbed),
       function(x) write.table(spbed[x], file=paste(path,x,'-',suffix,sep=""), sep = "\t",
                               quote=F, row.names=F,col.names=c("#chr","start","end")))
```
<br>    


#### Get genomic annotations of all peaks and strong peaks
+ are they biased for TSS?
+ HOMER annotatePeaks.pl
+ TODO
```{r annotate_pks, engine="bash"}
annotatePeaks.pl <filenmame> mm9 -annStats <filenmame>.annStats.txt > <filenmame>.annpks.txt

annotatePeaks.pl <filenmame>.bed mm9 -annStats <filenmame>.annStats.txt > <filenmame>.annpks.txt
```
<br>    


#### Create merged peak set and get normalized read counts 
+ DiffBind 
+ Used R 3.2.1 on Orchestra so didn't have to keep .bam locally
+ script called `a5.db.counts.R`
+ run with:
`module load stats/R/3.2.1`
`bsub -q priority -W 5:00 -R "rusage[mem=64000]" Rscript a5.db.counts.R`
```{r merge_and_count}
library(DiffBind)

##----- create sample sheet --------------------------------------------------------------------------------
path <- "/groups/cbdm-db/jrd26/ATAC_crossbatch/R/Analysis7/"

Peaks <- list.files(paste0(path, "bed/2rpm-filtered/"))

# create columns for sample sheet
SampleID <- unlist(strsplit(Peaks, split = "-2rpm.bed"))
Tissue <- c(rep('Colon',4),rep('Muscle',2),rep('Spleen',8),rep("VAT",2))
Factor <- unlist(strsplit(SampleID, split = "_rep1.2"))
Factor <- unlist(strsplit(Factor, split = "_rep1"))
Factor <- unlist(strsplit(Factor, split = "_rep2"))
Factor <- unlist(strsplit(Factor, split = "_rep3"))
Condition <- "Treg"
Treatment <- c('Batch1.2','Batch2','Batch1.2','Batch2',rep('Batch2',2),'Batch1','Batch2',
               'Batch1','Batch2',rep('Batch2',2),rep('Batch1',4))
Replicate <- rep(c('1','2'),8)
PeakCaller <- "homer"
PeakFormat <- "bed"
PeakPath <- list.files(paste0(path, "bed/2rpm-filtered/"), full.names = T)

path2 <- "/groups/cbdm-db/jrd26/ATAC_crossbatch/R/"
bamPath <- list.files(paste0(path2,"reads/"), full.names=T)

samples <- cbind(SampleID = SampleID, 
                 Tissue = Tissue, 
                 Factor = Factor, 
                 Condition = Condition,
                 Treatment = Treatment,
                 Replicate = Replicate,
                 bamReads = bamPath,
                 Peaks = PeakPath,
                 PeakCaller = PeakCaller,
                 PeakFormat = PeakFormat)
write.csv(samples, "samples.csv", row.names=F)


##-----loading data-----------------------------------------------------------------------------------
# create DBA object
ttreg <- dba(sampleSheet = "samples.csv", bRemoveRandom = T, minOverlap = 2)

# make consensus peakset from replicates
ttreg <- dba.peakset(ttreg, consensus = DBA_FACTOR)

# make consensus peakset from samples and count reads
ttreg <- dba.count(ttreg, peaks = ttreg$masks$Consensus, score = DBA_SCORE_RPKM)

# save dba to file
n <- 2  # save rpm filter value
dba.save(ttreg, file=paste0("a7-ttreg",n,'rpm-filtered'), dir=path, pre="dba_", ext="RData", bMinimize=F)

# export consensus peakset with read counts
# set filter
n <- 2
suffix <- paste('a7-ttreg-consensus-',n,'rpm-filtered-rpkm',sep="")
ttreg_con <- dba.peakset(ttreg, ttreg$masks$Consensus, bRetrieve = T, 
                         writeFile=paste0(path,suffix,'.txt'), DataType=DBA_DATA_FRAME)

write.csv(ttreg_con, file=paste0(path, suffix, '.csv'), row.names=F)

# save read count correlation heatmap
suffix <- paste('a7-ttreg-',n,'rpm-reads-heat',sep="")
pdf(paste0(path,suffix,'.pdf'), width=10, height=10, pagecentre = T)
par(oma = c(3,2,2,3))
dba.plotHeatmap(ttreg)
dev.off()

# save read count PCA
suffix <- paste('a7-ttreg-',n,'rpm-pca',sep="")
pdf(paste0(path,suffix,'.pdf'), width=10, height=10, pagecentre = T)
par(oma = c(3,2,2,3))
dba.plotPCA(ttreg, attributes=DBA_TISSUE, label=DBA_FACTOR, score=DBA_SCORE_RPKM)
dev.off()

```
<br>    


#### Filter peaks by replicate CV
+ import results of DiffBind counts
+ **give each peak a unique ID**
+ make separate df for each sample with replicate rpkm, mean, log2mean, cv , cvlog2 (cv2)
+ combine dfs into list
+ melt list 
+ ggplot mean vs cv2 for each sample
+ look at different cv cutoffs on browser
+ create function to filter by cv
+ apply function over sample list
+ recombine into single df for each peak, using peakID 
```{r cv_filter}

##--- import peak file with normalized counts -------------------------------------------------------------
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-filtered/csv/"
ttreg <- read.csv(file = paste(path,'a7-ttreg-consensus-2rpm-filtered-rpkm.csv',sep=""), header =T)


##----plot read count distributions after merge -------------------------------------------------------------
# set plots path
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-filtered/plots/"

# set file suffix
n <-2
suffix <- paste0('a7-ttreg-', n,'rpm-filtered-merged-counts-rpkm')

# plot and save
pdf(paste0(path,suffix,'.pdf'), width=8, height=6)
par(oma = c(4,1,0.5,1))
h <- 4 # set height of horizontal line
boxplot(log(ttreg[4:19],2), las = 2, cex.axis = 0.7, 
        ylab='log2 rpkm', 
        main=paste('merged atac peaks ','n=',nrow(ttreg),'; abline rpm=',h,sep=""))
abline(h=h, col = 'red')
dev.off()


##---- give each peak unique ID --------------------------------------------------------------------------------
peakName <- paste('peak_', 1:nrow(ttreg),sep="")
ttreg <- cbind(PeakID = peakName, ttreg)
# export 
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-filtered/csv/"
write.csv(ttreg, file = paste(path,'a7-ttreg-consensus-2rpm-filtered-rpkm-named.csv',sep=""), row.names=F)


##---- apply row stats functions to each sample ----------------------------------------------------------------
names(ttreg) # view column names

# create new df for each sample's stats
library(dplyr)
Cln_Nrp1n <- row_stats2(ttreg, "5","6")
Cln_Nrp1p <- row_stats2(ttreg, "7","8")
Mus <- row_stats2(ttreg, "9","10")
Spl_wCln_Nrp1n <- row_stats2(ttreg, "11","12")
Spl_wCln_Nrp1p <- row_stats2(ttreg, "13","14")
Spl_wMus <- row_stats2(ttreg,"15","16")
Spl_wVat <- row_stats2(ttreg,"17","18")
Vat <- row_stats2(ttreg, "19","20")

# combine the dfs into a list
stat.list <- list(Cln_Nrp1n, Cln_Nrp1p, Mus, Vat, Spl_wCln_Nrp1n, Spl_wCln_Nrp1p, Spl_wMus, Spl_wVat)
# name each element of the list
list.names <- c('Cln_Nrp1n', 'Cln_Nrp1p', 'Mus', 'Vat', 'Spl_wCln_Nrp1n', 'Spl_wCln_Nrp1p', 
                'Spl_wMus', 'Spl_wVat') 
names(stat.list) <- list.names

# rename the columns of each df
stat_names <- c('PeakID','Rep1_rpkm', 'Rep2_rpkm','Mean','Log2_mean', 'Log10_mean', 'Mean_of_log2',
                'CV','CV_of_log2')

for (i in seq_along(stat.list)) {
  colnames(stat.list[[i]]) <- stat_names
}
# check 
head(stat.list[[1]])

# create sample IDs
samples <- as.list(list.names)
sampleID <- lapply(samples, function(x) {rep(x,nrow(ttreg))})
# append sampleID to each df
ttreg.stats <- list()
for (i in 1:length(stat.list)) {
  ttreg.stats[[i]] <- cbind(SampleID = sampleID[[i]], stat.list[[i]])
}
# name list elements
names(ttreg.stats) <- list.names

# look over 
head(ttreg.stats[[1]])
head(ttreg.stats[[8]])


##----plot replicate mean and cvs --------------------------------------------------------------------------------
library(reshape2)
library(ggplot2)
# set plots path
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-filtered/plots/"

# get into shape for ggplot
slm <- melt(ttreg.stats, id.vars = colnames(ttreg.stats[[1]])) #[s]tat[l]ist[m]elted
slm$L1 <- NULL

# plot replicates against each other
p <- ggplot(slm, aes(x=log(Rep1_rpkm,2),y=log(Rep2_rpkm,2)))
p + geom_point(size= 0.7, shape = 1, alpha=0.6) +
  facet_wrap(~SampleID) + 
  theme_bw()
ggsave(paste0(path,'a7-rep-scatter-prefilter.png'), width=8, height=8)

# plot mean vs cv
p <- ggplot(slm, aes(x=Log2_mean, y=CV))
p + geom_point(size= 0.7, shape = 1, alpha=0.6) +
  facet_wrap(~SampleID) + 
  theme_bw()
ggsave(paste0(path,'a7-rep-cv-prefilter.png'), width=8, height=8)


##---- filter by max cv  --------------------------------------------------------------------------------------
# filter by cv <= 0.6
library(dplyr)
n <- 0.6
cv06.list <- lapply(ttreg.stats, filter, CV <= n)

# name list elements
names(cv06.list) <- list.names
  
# take a look at results
prefilter <- unlist(lapply(ttreg.stats, nrow))
postfilter <- unlist(lapply(cv06.list, nrow))
prefilter
postfilter

# get list into shape for plotting
cv06m <- melt(cv06.list, id.vars = colnames(cv06.list[[1]]))
cv06m$L1 <- NULL

# look at distribution of read counts 
p <- ggplot(cv06m, aes(x=Log2_mean))
p + geom_histogram(fill="white",color="black",binwidth=0.1) +
  facet_grid(SampleID~.) +
  geom_vline(xintercept =log(1,2)) +
  geom_vline(xintercept = log(2,2)) +
  geom_vline(xintercept = log(3,2)) +
  theme_bw()
 ggsave(paste0(path,'a7-rep-cv06-rpkm-hist.pdf'), width=8, height=8)
 
# plot replicates against each other after cv filter
p <- ggplot(cv06m, aes(x=log(Rep1_rpkm,2),y=log(Rep2_rpkm,2)))
p + geom_point(size= 0.7, shape = 1, alpha=0.6) +
  facet_wrap(~SampleID) + 
  theme_bw()
ggsave(paste0(path,'a7-rep-scatter-postfilter.png'), width=8, height=8)

# lookup and paste chr coordinates for each peak
library(dplyr)

cv06.list.bed <- lapply(cv06.list, function(x) { left_join(x,ttreg[1:4],by="PeakID")})
cv06.list.bed <- lapply(cv06.list.bed, function(x) { cbind(x[1:2],x[11:13],x[3:10])})
names(cv06.list.bed) <- list.names

# save list of cv-filtered dfs
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-cv06/RDa/"
save(cv06.list.bed, file = paste(path,'a7-ttreg-2rpm-','cv',n,'-filtered-list.RDa',sep=""))
# load
load(paste0(path,'a7-ttreg-2rpm-cv06-filtered-list.RDa'))

# export each df as .csv file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-cv06/csv/"
suffix <- paste('cv', n, '-filtered','.csv',sep="")
lapply(names(cv06.list.bed), 
       function(x) write.csv(cv06.list.bed[[x]], file=paste(path,x,'-2rpm-',suffix,sep=""), row.names=F))


##---- merge all the filtered peaks ------------------------------------------------------------------------------
# set path
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A7-all-ttreg/2rpm-cv06/csv/"

# get filenames
filenames <- list.files(path = path, pattern = ".csv", full.names=T)

# combine into a list
colClass <- c('factor','character','factor',rep('integer',2),rep('numeric',8))
pl <- lapply(filenames, read.csv, colClasses = colClass) # [p]eak[l]ist

# name list elements to match filenames 
filenames1 <- list.files(path=path, pattern=".csv")
sample.names <- strsplit(filenames1, split='-2rpm-')
sample.names <- unlist(lapply(sample.names, function(x) x[[1]]))
names(pl) <- sample.names
names(pl) # check

# remove extraneous columns
pl <- lapply(pl, function(x) x[1:7])
str(pl[[1]])

# create vector of new column names for rpkm columns
r1 <- c('_rpkm_r1')
r2 <- c('_rpkm_r2')
rpkm1 <- c(paste(sample.names,r1,sep=""),paste(sample.names,r2,sep=""))
rpkm1 <- rpkm1[order(rpkm1)]

# rename rpkm dfs 
namelist <- list()
for (i in 1:length(names(pl))) {
  ext <- c('_rpkm_r1','_rpkm_r2')
  namelist[[i]] <- paste(names(pl)[[i]],ext,sep="")
}

namelist2 <- list()
for (i in 1:length(names(pl))) {
  names1 <- colnames(pl[[1]][1:5])
  namelist2[[i]] <- c(names1, namelist[[i]])
}


for (i in seq_along(pl)) {
  colnames(pl[[i]]) <- namelist2[[i]]
}

lapply(pl, head) # check 
pl <- lapply(pl, function(x) {x[-1]}) # remove SampleID
lapply(pl, head) # check 

# extract individual df
list2env(pl, .GlobalEnv)

# merge
hcp <- inner_join(Cln_Nrp1n,Cln_Nrp1p, by='PeakID') #[h]igh[c]onfidence[p]eaks
hcp <- inner_join(hcp, Mus, by='PeakID')
hcp <- inner_join(hcp, Spl_wCln_Nrp1n, by='PeakID')
hcp <- inner_join(hcp, Spl_wCln_Nrp1p, by = 'PeakID')
hcp <- inner_join(hcp, Spl_wMus, by= 'PeakID')
hcp <- inner_join(hcp, Spl_wVat, by='PeakID')
hcp <- inner_join(hcp, Vat, by = 'PeakID')

# remove extraneous columns
chr <- grepl(pattern = c("CHR*") ,colnames(hcp))
start <- grepl(pattern = c("START*"), colnames(hcp))
end <- grepl(pattern = c("END*"), colnames(hcp))
hcp <- hcp[, !(chr | start | end)]

# add peak coords 
hcp.df <- left_join(hcp, ttreg[1:4], by = "PeakID") # hcp.[d]ata[f]rame
# rearrange columns
hcp.df <- cbind(hcp.df[1],hcp.df[18:20],hcp.df[2:17])
names(hcp.df)

# plot scatter matrices to get idea of pair-wise FC
library(GGally)
#test <- hcp.df
test2 <- data.frame(lapply(hcp.df[5:20], log, 2))
ncol(test2)
jd_ggscatmat(test2[1:8])
jd_ggscatmat(test2[c(1:4,5:6,15:16)])

```
<br>  


#### Quantile normalize read count values
**Pseudo:**  
+ Plot distributions of read counts in the merged peak set for all samples 
+ Quantile normalize using bioconductor...
+ plot distributions of read counts in the merged peak set post QN
```{r qn}
library(reshape2)
library(ggplot2)

# import peak file
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A5-all-ttreg/2rpm-filtered/csv/"

ttreg <- read.csv(file = paste(path,'a5-ttreg-consensus-2rpm-filtered-rpkm.csv',sep=""), header =T)

##----plot read count distributions after merge -------------------------------------------------------------
# set plots path
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A5-all-ttreg/2rpm-filtered/plots/"

# set file suffix
suffix <- paste0('a5-ttreg-', n,'rpm-filtered-merged-counts-rpkm')

# plot and save
pdf(paste0(path,suffix,'.pdf'), width=8, height=6)
par(oma = c(4,1,0.5,1))
h <- 4 # set height of horizontal line
boxplot(log(ttreg[4:19],2), las = 2, cex.axis = 0.7, 
        ylab='log2 rpkm', 
        main=paste('merged atac peaks ','n=',nrow(ttreg),'; abline rpm=',h,sep=""))
abline(h=h, col = 'red')
dev.off()

# try rotated view
# boxplot(log(ttreg[4:19],2), las = 2, cex.axis = 0.5, horizontal =T)

##---- quantile normalization ----------------------------------------------------------------------------
library(preprocessCore)

# create matrix of rpm values
ttrm <- as.matrix(ttreg[,4:19]) # [t][t][r]eg[m]atrix

# qn using preprocess core
ttrqn.mat <- normalize.quantiles(ttrm) #[t][t][r]eg[q]uantile[n]ormalized[mat]rix

# set file suffix
suffix <- paste0('a5-ttreg-', n,'rpm-filtered-merged-counts-rpkm-qn')

##----plot read count distributions after merge then qn ---------------------------------------------------

# plot and save
pdf(paste0(path,suffix,'.pdf'), width=8, height=6)
par(oma = c(4,1,0.5,1))
h <- 4 # set height of horizontal line
boxplot(log(ttrqnmat,2), las = 2, cex.axis = 0.7, 
        ylab='log2 rpkm', 
        main=paste('merged atac peaks ','n=',nrow(ttreg),'; abline rpm=',h,sep=""))
abline(h=h, col = 'red')
dev.off()

##--- export qn rpkm values -------------------------------------------------------------------------------
path <- "/Volumes/JD_WD2/JRD_CBDMLab/1_JRD_CBDM_PROJECTS/ProjectFolders/T-TregEpigenome/Data/1_Experimental/ATAC/Analyses/A5-all-ttreg/2rpm-filtered/RDa/"
suffix <- paste0('a5-ttreg-', n,'rpm-filtered-merged-counts-rpkm-qn-mat')
save(ttrqnmat, file=paste0(path,suffix,'.RDa'))

# as df with chrom info pasted on
# add chrom coordinates info
ttrqn.df <- cbind(ttreg[1:3],ttrqnmat)

suffix <- paste0('a5-ttreg-', n,'rpm-filtered-merged-counts-rpkm-qn-df')
save(ttrqn.df, file=paste0(path,suffix,'.RDa'))
```
<br>  





